{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кратко об этом исследовании\n",
    "Данные из Остинского центра животных, то есть приюта, -- с 1 октября 2013 по **март 2016**. \n",
    "\n",
    "## Цель\n",
    "\n",
    "Требуется предсказать судьбу каждого животного по данным о нём сведениям. По сути, обычная задача категоризации. Классы: Adoption, Died, Euthanasia, Return to owner, Transfer. \n",
    "\n",
    "Все классы считаем одинаково важными все зависимости от представленности в выборке. Качество предсказаний оценивается поэтому с помощью macro-averaged F1 score.\n",
    "\n",
    "## Методы\n",
    "### Предобработка\n",
    "\n",
    "**Имена**\n",
    "\n",
    "С ними не удобно возиться, там много отсутствующих данных и их использование не оказывает явного влияния. Так что были удалены.\n",
    "\n",
    "**Даты и возраст**\n",
    "\n",
    "Помимо предложеного варианта, пробовал учитывать только год из DataTime как категориальный признак (значительной разницы не дает, а порой даже делает хуже). Пробовал несколько разных скейлеров (нормализаторов?), таких как StandartScaler и MinMaxScaler.\n",
    "\n",
    "**Порода и цвет**\n",
    "\n",
    "Пробовал разные энкодеры на категориальных признаках, а так же векторизацию. Идейно ожидал, что именно векторизация (с последующим применением энкодера или без него) даст хорошую предобработку для породы и цвета, однако на практике ничего хорошего почему-то не выходило. Пробовал в разных комбинациях учитывать и не учитывать эти признаки.\n",
    "\n",
    "**Пол**\n",
    "\n",
    "Пробовал делить и не делить на факт стерилизованности и пол отдельно. В среднем лучше себя показал раздельный вариант.\n",
    "\n",
    "**Moreover**\n",
    "\n",
    "Пробовал сбалансировать распределение меток у df_train с помощью догенерации данных алгоритмами SMOTE, ADASYN. Выглядело интересно, но результата не принесло. Возможно, при таком изначальном соотношении меток, на правильность предсказания редких меток (3, 4) проще не обращать внимания.\n",
    "\n",
    "В целом для каждой исследуемой модели испытывались разные комбинации предобработки, параметров, энкодеров, векторизации, нормализации. Самые лучшеи результаты обычно выходили для комбинации OrdinalEncoder + StandartScaler без лишних наворотов.\n",
    "\n",
    "### Модели\n",
    "\n",
    "**LogisticRegression**: Ничего хорошего не вышло, но я не сильно и пытался - кажется эта модель не очень подходит по своей сути.\n",
    "\n",
    "**DecisionTreeClassifier**: Пробовал на более менее стандартных параметрах, быстро перешел на леса.\n",
    "\n",
    "**RandomForestClassifier**: Самая удачная модель в итоге. Сделал N запусков GridSearch на ней, перебираемые параметры будут ниже в коде.\n",
    "\n",
    "**GradientBoostingClassifier**: Пробовал, но быстро перешел на реализацию XGBClassifier этой модели, так как где-то вычитал, что она реализована лучше, чем в Sklearn.\n",
    "\n",
    "**XGBClassifier**: Вторая по удачности модель после RFC, но доститчь на ней высоких результатов так и не вышло. Сделал N запусков GridSearch на ней, перебираемые параметры будут ниже в коде. В целом эта модель была главным источником зря потраченных усилий.\n",
    "\n",
    "**VotingClassifier**: То, что делается в итоге для RFC с разными параметрами. Действительно помогает. Пробовал заставить голосовать разные модели (в основном RFC с разными параметрами) в разном количестве. Менял параметр voting=\"soft\"/\"hard\".\n",
    "\n",
    "\n",
    "## Результаты\n",
    "\n",
    "Про успехи и потраченные силы, кажется, было напсиано выше. В целом кажется, что для такого набора данных, с такими признаками и распределнием меток, лучше всего подходят логические классификаторы, основанные на построении деревьев. \n",
    "\n",
    "Смотря на итоговый рейтинг, кажется, что я уперся в некий потолок, где нужна была более глубокая предобработка, а не перебор параметров у моделей. В целом можно было бы вручную поработать с данными, поискать побольше корреляций разных параметров с метками на df_train, построить разные графики. Возможно, стоило бы вручную тщательно поработать с породами и цветами, перегруппировать эти данные, разбить на более широкие классы. Я никогда до этого не занимался ничем похожим на такое задание, так что в качестве главной морали я вынес то, что по сути надо проводить целое исследование о том, как устроены конкретные данные.\n",
    "В общем интересно, что делали коллеги, получившие счет больше 0.5. Будет очень полезно, если вы после проверки работ вышлете в чат какую-то сводку по тому, за счет чего у людей получалось сделать хорошо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конфиги и константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME2LABEL = {\"Adoption\" : 0, \n",
    "                 \"Transfer\": 1, \n",
    "                 \"Return_to_owner\": 2, \n",
    "                 \"Euthanasia\": 3, \n",
    "                 \"Died\": 4\n",
    "                }\n",
    "LABEL2OUTCOME = {v: k for k,v in OUTCOME2LABEL.items()}\n",
    "FOLD_K = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\denis\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\denis\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\denis\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вроде все версии используемых библиотек стояли последние \n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse \n",
    "from sklearn import tree \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\", encoding=\"utf-8\")\n",
    "df_test = pd.read_csv(\"test.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление строк, где не хватает данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем имена, так как это довольно бесполезный параметр. Удаляем строки df_train, где не хватет каких-то данных (15 штук без имен, не значительная потеря). В df_test заменяем пустые места на \"Unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop([\"Name\"], axis=1, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "df_test.drop([\"Name\"], axis=1, inplace=True)\n",
    "df_test.fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка признаков\n",
    "\n",
    "### Даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_dates2number(date_series: pd.Series):\n",
    "    return pd.to_datetime(date_series).values.astype(np.int64) // 10 ** 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Возраст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем возраст к возрасту в днях. Для тех, у кого возраст исходно неизвестен, поставим среднее значение по известным, примерно равное 794 дням (для этого у \"Unknown\" сначала было выставлено значение в 0 дней и посчитано среднее по остальным)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, \"разбирающая\" строки с возрастом \n",
    "def age_to_days(age): \n",
    "    age_split = age.split()\n",
    "    if age == \"Unknown\":\n",
    "        age_in_days = 794\n",
    "    elif age_split[1].startswith(\"year\"):\n",
    "        age_in_days = int(age_split[0]) * 365\n",
    "    elif age_split[1].startswith(\"month\"):\n",
    "        age_in_days = int(age_split[0]) * 30\n",
    "    elif age_split[1].startswith(\"week\"):\n",
    "        age_in_days = int(age_split[0]) * 7\n",
    "    elif age_split[1].startswith(\"day\"):\n",
    "        age_in_days = int(age_split[0])\n",
    "    return age_in_days\n",
    "\n",
    "# Функция-преобразователь для DataFrame:\n",
    "def Age_to_days_series(df: pd.Series):\n",
    "    df = df.apply(lambda x: age_to_days(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пол"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем пол на стерилизованность и, собственно, пол."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция выделения из строки факта стерилизованности\n",
    "def intactness(sex_and_intact: str):\n",
    "    if \"Intact\" in sex_and_intact:\n",
    "        return \"Intact\"\n",
    "    elif \"Neutred\" or \"Spayed\" in sex_and_intact:\n",
    "        return \"N or S\"  # Neutred or Spayed\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Функция выделения из строки пола\n",
    "def sex(sex_and_intact: str):\n",
    "    if \"Male\" in sex_and_intact:\n",
    "        return \"Male\"\n",
    "    elif \"Female\" in sex_and_intact:\n",
    "        return \"Female\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Функция-преобразователь для DataFrame для факта стерилизации:\n",
    "def SexuponOutcome_to_intactness(df: pd.Series):\n",
    "    df = df.apply(lambda x: intactness(x))\n",
    "    return df\n",
    "\n",
    "# Функция-преобразователь для DataFrame для пола:\n",
    "def SexuponOutcome_to_sex(df: pd.Series):\n",
    "    df = df.apply(lambda x: sex(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Порода, цвет и тип животного"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будут напрямую обрабатываться через OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Единая матрица признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df, encoder=None, scaler=None):\n",
    "    \n",
    "    # Используем написанные ранее функции для преобразования признаков \"DateTime\", \"SexuponOutcome\", \"AgeuponOutcome\"\n",
    "    df[\"DateTime\"] = pandas_dates2number(df[\"DateTime\"])  # Время\n",
    "    \n",
    "    df[\"intactness\"] = SexuponOutcome_to_intactness(df[\"SexuponOutcome\"])  # Факт стерилизованности\n",
    "    df[\"Sex\"] = SexuponOutcome_to_sex(df[\"SexuponOutcome\"])  # Пол\n",
    "    df.drop([\"SexuponOutcome\"], axis=1, inplace=True)\n",
    "    \n",
    "    df[\"Age\"] = Age_to_days_series(df[\"AgeuponOutcome\"])  # Возраст\n",
    "    df.drop([\"AgeuponOutcome\"], axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "    columns_categorical = [\"AnimalType\", \"Color\", \"Breed\", \"intactness\", \"Sex\"]\n",
    "    columns_real = [\"DateTime\", \"Age\"]\n",
    "    \n",
    "    \n",
    "    # Для columns_categorical используем OrdinalEncoder\n",
    "    if encoder is None:\n",
    "        encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "        encoder.fit(df[columns_categorical])\n",
    "\n",
    "    encoded_categorical_features = encoder.transform(df[columns_categorical])\n",
    "    cat_feature_names = encoder.categories_   # Новые названия категориальных колонок\n",
    "    \n",
    "    # Для columns_real используем StandardScaler\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[columns_real])\n",
    "\n",
    "    scaled_real_features = scaler.transform(df[columns_real])\n",
    "\n",
    "    # Соединяем обработанные признаки в единую матрицу X\n",
    "    X = np.hstack([encoded_categorical_features, scaled_real_features]) \n",
    "    \n",
    "    # Передаем матрицу X, новые названия колонок (не знаю зачем) и \n",
    "    # \"правильные\" encoder и scaler для использования при преобразовании df_test\n",
    "    return X, list(cat_feature_names) + [\"DateTime\", \"Age\"], encoder, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание матриц для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, fnames, encoder, scaler = prepare_features(df_train)\n",
    "y_train = df_train[\"Outcome\"]\n",
    "X_test, _, _, _ = prepare_features(df_test, encoder, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры для GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, с таким количеством параметров перебор шел бы слишком долго, поэтому в реальности запускалось много разных более \"узких\" GridSearch или использовался метод постепенного уточнения/сужения разброса параметров в последовательных GridSearch. Так что здесь просто представлены самые полные матрицы перебираемых параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_for_RFC = {\n",
    "    \"n_estimators\": [50, 100, 150, 200, 250, 300, 400, 500],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"max_samples\": [None, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    \"min_samples_leaf\": [2, 3, 5, 8, 10],\n",
    "    \"min_samples_split\": [2, 3, 5, 8, 10],\n",
    "    \"class_weight\": [None, \"balanced_subsample\"],\n",
    "    \"bootstrap\": [True]}\n",
    "# И примерно то же самое для RFC при bootstrap=False (В таком случае max_samples=None и class_weight=None/\"balanced\")\n",
    "\n",
    "# Перебирались также такие парамтеры для XGBClassifier, но это не дало значительного улучшения\n",
    "params_for_XGB = {\n",
    "    \"n_estimators\": [200, 400, 800, 1000],\n",
    "    \"learning_rate\": [0.03, 0.07, 0.1],\n",
    "    \"max_depth\": [2, 4, 6, 8],\n",
    "    \"objective\": [\"multi:softprob\"],\n",
    "    \"colsample_bytree\": [0.4, 0.6, 0.8, 1],\n",
    "    \"reg_lambda\": [0.1, 0.3, 1, 3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример производимого GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscores = [\"f1_macro\", \"f1_micro\", \"neg_log_loss\"]  # На самом деле по наблюдениям можно использовать только \"f1_macro\"\\n\\nfor score in scores:\\n    \\n    print(\"# Tuning for %s\" % score)\\n    print()\\n\\n    cv = StratifiedKFold(n_splits=2, random_state=1, shuffle=True)\\n    clf_RFC = RandomForestClassifier(n_jobs=-1, random_state=1)\\n    \\n    # поиск по заданной решётке параметров\\n    clf_grid = GridSearchCV(clf_RFC, params_for_RFC, scoring=score, n_jobs=-1, cv=cv, verbose=2)\\n    \\n    # запускаем поиск\\n    clf_grid.fit(X_train, y_train)\\n    \\n    # Вывод лучших парметров\\n    print(\"Best params on dev set:\")\\n    print(clf_grid.get_params())\\n    print()\\n    \\n    # обучаем на всём с \"лучшими\" параметрами\\n    best_RFC = clf_grid.best_estimator_\\n    best_RFC.fit(X_train, y_train)\\n    y_pred = best_RFC.predict(X_test)\\n    \\n    # Запись полученных данных\\n    pd.DataFrame({\"ID\": df_test[\"ID\"], \"Outcome\": y_pred}).to_csv(\"submission_\" + score + \".csv\", index=None)\\n'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример производимого GridSearch\n",
    "\n",
    "\"\"\"\n",
    "scores = [\"f1_macro\", \"f1_micro\", \"neg_log_loss\"]  # На самом деле по наблюдениям можно использовать только \"f1_macro\"\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    print(\"# Tuning for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=2, random_state=1, shuffle=True)\n",
    "    clf_RFC = RandomForestClassifier(n_jobs=-1, random_state=1)\n",
    "    \n",
    "    # поиск по заданной решётке параметров\n",
    "    clf_grid = GridSearchCV(clf_RFC, params_for_RFC, scoring=score, n_jobs=-1, cv=cv, verbose=2)\n",
    "    \n",
    "    # запускаем поиск\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Вывод лучших парметров\n",
    "    print(\"Best params on dev set:\")\n",
    "    print(clf_grid.get_params())\n",
    "    print()\n",
    "    \n",
    "    # обучаем на всём с \"лучшими\" параметрами\n",
    "    best_RFC = clf_grid.best_estimator_\n",
    "    best_RFC.fit(X_train, y_train)\n",
    "    y_pred = best_RFC.predict(X_test)\n",
    "    \n",
    "    # Запись полученных данных\n",
    "    pd.DataFrame({\"ID\": df_test[\"ID\"], \"Outcome\": y_pred}).to_csv(\"submission_\" + score + \".csv\", index=None)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лучшие параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле, лучшие параметры выходили разными на разных запусках GridSearch (со слегка разным перебором) и они давали очень близкие оценки на Public leaderboard, поэтому я взял некоторые лучшие и устроил голосование классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Некоторые лучшие при bootstrap=True\n",
    "params_for_RFC1 = {\n",
    "    \"n_estimators\": [100, 150, 200, 250, 300, 400],  # Бывает удачно при довольно разных n_estimators\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"max_depth\": [20, 30],\n",
    "    \"max_samples\": [0.3, 0.4],\n",
    "    \"min_samples_leaf\": [5, 8],\n",
    "    \"min_samples_split\": [2, 3, 5, 8, 10],  # Тут бывает любое из этих значений, не сильно влияет на счет\n",
    "    \"class_weight\": [\"balanced_subsample\"],\n",
    "    \"bootstrap\": [True]}\n",
    "\n",
    "# Некоторые лучшие при bootstrap=False\n",
    "params_for_RFC2 = {\n",
    "    \"n_estimators\": [100, 150, 200],  # Бывает удачно при довольно разных n_estimators, но в среднем стали поменьше, чем с True\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"max_depth\": [None, 20, 30],\n",
    "    \"min_samples_leaf\": [3, 5],\n",
    "    \"min_samples_split\": [2, 3, 5, 8, 10],  # Тут бывает любое из этих значений, не сильно влияет на счет\n",
    "    \"class_weight\": [\"balanced\"],\n",
    "    \"bootstrap\": [False]}\n",
    "\n",
    "# XGBoosting. На самом деле лучшие результаты он показывал при всех дефолтных параметрах, \n",
    "# разве что objective=\"multi:softprob\" указать полезно, что и отражено во варианте, используемом при голосовании"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификаторы для Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я не придумал, как задать все эти классификаторы красиво.\n",
    "\n",
    "XGBoosting был включен главным образом потому, что я потратил на попытки довести его до ума несколько дней, а потом RFC оказались лучше, но мне все таки хотелось его куда-нибудь запихнуть)\n",
    "\n",
    "Также, смотря на итоговые баллы для разных сабмитов, стоит отметить, что лучший вариант был не при таком относительно хаотичном голосовании 8 моделей, а при голосовании 2 деревьев и XGB (но вообще это все похоже на \"как повезет\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifie с bootstrap=True\n",
    "clf1 = RandomForestClassifier(bootstrap=True, class_weight=\"balanced_subsample\", \n",
    "                              max_depth=20, max_samples=0.3, min_samples_leaf=5, \n",
    "                              min_samples_split=2, n_estimators=100, n_jobs=-1,\n",
    "                              random_state=1)\n",
    "\n",
    "clf2 = RandomForestClassifier(bootstrap=True, class_weight=\"balanced_subsample\",\n",
    "                              max_depth=20, max_samples=0.3, min_samples_leaf=8, \n",
    "                              min_samples_split=2, n_estimators=300, n_jobs=-1, \n",
    "                              random_state=1)\n",
    "\n",
    "clf3 = RandomForestClassifier(bootstrap=True, class_weight=\"balanced_subsample\", \n",
    "                              max_depth=20, max_samples=0.4, min_samples_leaf=8, \n",
    "                              min_samples_split=10, n_estimators=250, n_jobs=-1, \n",
    "                              random_state=1)\n",
    "\n",
    "clf4 = RandomForestClassifier(bootstrap=True, class_weight=\"balanced_subsample\", \n",
    "                              max_depth=30, max_samples=0.4, min_samples_leaf=5, \n",
    "                              min_samples_split=2, n_estimators=400, n_jobs=-1, \n",
    "                              random_state=1)\n",
    "\n",
    "# RandomForestClassifie с bootstrap=False\n",
    "clf5 = RandomForestClassifier(bootstrap=False, class_weight=\"balanced\", \n",
    "                              max_depth=None, max_samples=None, min_samples_leaf=5, \n",
    "                              min_samples_split=10, n_estimators=100, n_jobs=-1, \n",
    "                              random_state=1)\n",
    "\n",
    "clf6 = RandomForestClassifier(bootstrap=False, class_weight=\"balanced\", \n",
    "                              max_depth=20, max_samples=None, min_samples_leaf=3, \n",
    "                              min_samples_split=3, n_estimators=100, n_jobs=-1, \n",
    "                              random_state=1)\n",
    "\n",
    "clf7 = RandomForestClassifier(bootstrap=False, class_weight=\"balanced\", \n",
    "                              max_depth=30, max_samples=None, min_samples_leaf=5,\n",
    "                              min_samples_split=5, n_estimators=150, n_jobs=-1, \n",
    "                              random_state=1)\n",
    "\n",
    "# XGBoosting\n",
    "clf_xgb = XGBClassifier(objective='multi:softprob',n_jobs=-1,seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf_xgb]\n",
    "clfs_names = [\"clf1\", \"clf2\", \"clf3\", \"clf4\", \"clf5\", \"clf6\", \"clf7\", \"clf_xgb\"]\n",
    "clfs_zip = list(zip(clfs_names, clfs))  # Создаем список вида [(\" \" , ),(\" \" , ),...] \n",
    "\n",
    "clf_vot = VotingClassifier(estimators=clfs_zip, voting=\"soft\", n_jobs=-1) \n",
    "clf_vot.fit(X_train, y_train)\n",
    "y_pred = clf_vot.predict(X_test)\n",
    "\n",
    "# Записываем полученные данные в файл\n",
    "pd.DataFrame({\"ID\": df_test[\"ID\"], \"Outcome\": y_pred}).to_csv(\"submission_voting\" + \".csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
